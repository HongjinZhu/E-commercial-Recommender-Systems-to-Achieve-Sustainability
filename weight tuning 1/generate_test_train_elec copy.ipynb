{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bc8c23f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        userId  itemId  rating   timestamp  sust\n",
      "0            0       0     2.0  1429401600     1\n",
      "1            1       0     5.0  1425427200     1\n",
      "2            2       0     5.0  1404604800     1\n",
      "3            3       0     5.0  1403049600     1\n",
      "4            4       0     5.0  1400112000     1\n",
      "...        ...     ...     ...         ...   ...\n",
      "224674    7894   19667     5.0  1471305600     0\n",
      "224675   11104   19668     2.0  1474070400     0\n",
      "224676   10084   12789     4.0  1533427200     0\n",
      "224677   16591   12791     2.0  1520899200     0\n",
      "224678   10784   12793     1.0  1533081600     0\n",
      "\n",
      "[224679 rows x 5 columns]\n",
      "Range of userId is [0, 19427]\n",
      "Range of itemId is [0, 19668]\n",
      "user_pool size:  19428\n",
      "item_pool size:  19669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuho\\AppData\\Local\\Temp\\ipykernel_22060\\3204605703.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ratings['rating'][ratings['rating'] > 0] = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interact_status: \n",
      "        userId                                   interacted_items\n",
      "0           0                   {0, 1922, 6344, 4205, 367, 1266}\n",
      "1           1  {0, 6433, 7586, 7872, 8751, 4527, 5423, 5425, ...\n",
      "2           2            {0, 2214, 4327, 12391, 12135, 6476, 56}\n",
      "3           3              {0, 549, 1352, 2601, 3219, 661, 1591}\n",
      "4           4  {0, 10402, 6340, 9798, 4360, 8137, 6899, 6612,...\n",
      "...       ...                                                ...\n",
      "19423   19423   {10624, 8775, 11565, 10834, 12082, 11896, 10809}\n",
      "19424   19424  {9760, 9060, 9765, 18312, 9930, 12618, 12461, ...\n",
      "19425   19425        {9378, 9928, 9170, 9366, 18361, 9370, 9853}\n",
      "19426   19426     {18272, 9762, 9201, 9202, 18263, 18269, 18270}\n",
      "19427   19427    {9964, 19249, 11666, 18675, 19250, 19251, 9982}\n",
      "\n",
      "[19428 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuho\\AppData\\Local\\Temp\\ipykernel_22060\\3204605703.py:83: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, 99))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after sampling interact_status: \n",
      "        userId                                   interacted_items  \\\n",
      "0           0                   {0, 1922, 6344, 4205, 367, 1266}   \n",
      "1           1  {0, 6433, 7586, 7872, 8751, 4527, 5423, 5425, ...   \n",
      "2           2            {0, 2214, 4327, 12391, 12135, 6476, 56}   \n",
      "3           3              {0, 549, 1352, 2601, 3219, 661, 1591}   \n",
      "4           4  {0, 10402, 6340, 9798, 4360, 8137, 6899, 6612,...   \n",
      "...       ...                                                ...   \n",
      "19423   19423   {10624, 8775, 11565, 10834, 12082, 11896, 10809}   \n",
      "19424   19424  {9760, 9060, 9765, 18312, 9930, 12618, 12461, ...   \n",
      "19425   19425        {9378, 9928, 9170, 9366, 18361, 9370, 9853}   \n",
      "19426   19426     {18272, 9762, 9201, 9202, 18263, 18269, 18270}   \n",
      "19427   19427    {9964, 19249, 11666, 18675, 19250, 19251, 9982}   \n",
      "\n",
      "                                          negative_items  \\\n",
      "0      {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "1      {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "2      {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "3      {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "4      {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "...                                                  ...   \n",
      "19423  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "19424  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "19425  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "19426  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "19427  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "\n",
      "                                        negative_samples  \n",
      "0      [12629, 13787, 1329, 8490, 16759, 15928, 13274...  \n",
      "1      [13754, 19006, 9029, 14775, 16154, 11721, 2700...  \n",
      "2      [17843, 9208, 4422, 7873, 15795, 11546, 9438, ...  \n",
      "3      [9543, 292, 4543, 4955, 8899, 10932, 11066, 12...  \n",
      "4      [11861, 17915, 4962, 3434, 19548, 15998, 4866,...  \n",
      "...                                                  ...  \n",
      "19423  [35, 16135, 15527, 7850, 10920, 8482, 18766, 1...  \n",
      "19424  [3798, 568, 4536, 16838, 17187, 4719, 6173, 10...  \n",
      "19425  [9300, 12823, 2584, 16934, 14015, 6390, 3794, ...  \n",
      "19426  [9932, 10401, 13820, 1353, 5035, 7856, 16818, ...  \n",
      "19427  [9867, 6538, 2412, 12795, 12651, 11851, 2971, ...  \n",
      "\n",
      "[19428 rows x 4 columns]\n",
      "select and rearrange columns\n",
      "sort by timestamp descend\n",
      "        userId  itemId  rating   timestamp  sust  rank_latest\n",
      "0            0       0     1.0  1429401600     1          1.0\n",
      "1            1       0     1.0  1425427200     1          1.0\n",
      "2            2       0     1.0  1404604800     1          4.0\n",
      "3            3       0     1.0  1403049600     1          1.0\n",
      "4            4       0     1.0  1400112000     1         11.0\n",
      "...        ...     ...     ...         ...   ...          ...\n",
      "224674    7894   19667     1.0  1471305600     0          3.0\n",
      "224675   11104   19668     1.0  1474070400     0          6.0\n",
      "224676   10084   12789     1.0  1533427200     0          1.0\n",
      "224677   16591   12791     1.0  1520899200     0          2.0\n",
      "224678   10784   12793     1.0  1533081600     0          1.0\n",
      "\n",
      "[224679 rows x 6 columns]\n",
      "size of test 19428, size of train 205251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhuho\\AppData\\Local\\Temp\\ipykernel_22060\\3204605703.py:137: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  test_ratings['negatives'] = test_ratings['negative_items'].apply(lambda x: random.sample(x, num_negatives))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId  itemId  rating  \\\n",
      "0           0       0     1.0   \n",
      "1           1       0     1.0   \n",
      "2           3       0     1.0   \n",
      "3           6       1     1.0   \n",
      "4          21       5     1.0   \n",
      "...       ...     ...     ...   \n",
      "19423   14064   19663     1.0   \n",
      "19424   13002   19664     1.0   \n",
      "19425    8237   19667     1.0   \n",
      "19426   10084   12789     1.0   \n",
      "19427   10784   12793     1.0   \n",
      "\n",
      "                                          negative_items  \\\n",
      "0      {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "1      {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "2      {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "3      {0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "4      {0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "...                                                  ...   \n",
      "19423  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "19424  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "19425  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "19426  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "19427  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "\n",
      "                                               negatives  \n",
      "0      [18256, 18048, 19528, 5326, 18104, 3454, 6258,...  \n",
      "1      [7675, 9530, 15213, 5915, 7154, 11088, 4685, 7...  \n",
      "2      [87, 17775, 14556, 138, 10913, 6616, 6211, 194...  \n",
      "3      [5791, 9783, 3003, 1378, 15587, 8100, 14809, 1...  \n",
      "4      [7282, 7091, 2447, 12245, 15191, 10498, 5041, ...  \n",
      "...                                                  ...  \n",
      "19423  [5696, 1887, 16659, 14315, 14500, 13752, 7340,...  \n",
      "19424  [11134, 4731, 9298, 17665, 16794, 12689, 14532...  \n",
      "19425  [9311, 3663, 18818, 16313, 15989, 15697, 14204...  \n",
      "19426  [6480, 4769, 8255, 12686, 3550, 13701, 12900, ...  \n",
      "19427  [16886, 9971, 3568, 4881, 7065, 2858, 17400, 6...  \n",
      "\n",
      "[19428 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import os\n",
    "\n",
    "# electronics = pd.read_csv('amazonRatings.csv', names=['index','userId','productId','Rating','timestamp'])\n",
    "# electronics = electronics.drop([0])\n",
    "# electronics = electronics.drop(['index'], axis=1)\n",
    "# electronics.to_csv('cleanedElec.csv',index=False,header=False)\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "class DataProcess(object):\n",
    "    def __init__(self, filename):\n",
    "        self._filename = filename\n",
    "        self._loadData()\n",
    "        self._preProcess()\n",
    "        self._binarize(self._originalRatings)\n",
    "        # 对'userId'这一列的数据，先去重，然后构成一个用户列表\n",
    "        self._userPool = set(self._originalRatings['userId'].unique())\n",
    "        self._itemPool = set(self._originalRatings['itemId'].unique())\n",
    "        print(\"user_pool size: \", len(self._userPool))\n",
    "        print(\"item_pool size: \", len(self._itemPool))\n",
    "\n",
    "        self._select_Negatives(self._originalRatings)\n",
    "        self._split_pool(self._preprocessRatings)\n",
    "\n",
    "    def _loadData(self):\n",
    "        self._originalRatings = pd.read_csv(self._filename,names=['uid','mid','rating','timestamp','sust'])\n",
    "        is_multi_item = self._originalRatings['mid'].value_counts()>2\n",
    "        self._originalRatings = self._originalRatings[self._originalRatings['mid'].isin(is_multi_item[is_multi_item].index)]\n",
    "        is_multi_user=self._originalRatings['uid'].value_counts()>6\n",
    "        self._originalRatings = self._originalRatings[self._originalRatings['uid'].isin(is_multi_user[is_multi_user].index)]\n",
    "        return self._originalRatings\n",
    "\n",
    "    def _preProcess(self):\n",
    "        \"\"\"\n",
    "        对user和item都重新编号，这里这么做的原因是因为，模型的输入是one-hot向量，需要把user和item都限制在Embedding的长度之内，\n",
    "        模型的两个输入的长度分别是user和item的数量，所以要重新从0编号。\n",
    "        \"\"\"\n",
    "        # 1. 新建名为\"userId\"的列，这列对用户从0开始编号\n",
    "        user_id = self._originalRatings[['uid']].drop_duplicates().reindex()\n",
    "        user_id['userId'] = np.arange(len(user_id)) #根据user的长度创建一个数组\n",
    "        # 将原先的DataFrame与user_id按照\"uid\"这一列进行合并\n",
    "        self._originalRatings = pd.merge(self._originalRatings, user_id, on=['uid'], how='left')\n",
    "\n",
    "        # 2. 对物品进行重新排列\n",
    "        item_id = self._originalRatings[['mid']].drop_duplicates()\n",
    "        item_id['itemId'] = np.arange(len(item_id))\n",
    "        self._originalRatings = pd.merge(self._originalRatings, item_id, on=['mid'], how='left')\n",
    "\n",
    "        # 按照['userId', 'itemId', 'rating', 'timestamp']的顺序重新排列\n",
    "        self._originalRatings = self._originalRatings[['userId', 'itemId', 'rating', 'timestamp','sust']]\n",
    "        print(self._originalRatings)\n",
    "        print('Range of userId is [{}, {}]'.format(self._originalRatings.userId.min(), self._originalRatings.userId.max()))\n",
    "        print('Range of itemId is [{}, {}]'.format(self._originalRatings.itemId.min(), self._originalRatings.itemId.max()))\n",
    "\n",
    "    def _binarize(self, ratings):\n",
    "        \"\"\"\n",
    "        binarize data into 0 or 1 for implicit feedback\n",
    "        \"\"\"\n",
    "        ratings = deepcopy(ratings)\n",
    "        ratings['rating'][ratings['rating'] > 0] = 1.0\n",
    "        self._preprocessRatings = ratings\n",
    "        # print(\"binary: \\n\", self._preprocessRatings)\n",
    "\n",
    "    def _select_Negatives(self, ratings):\n",
    "        \"\"\"\n",
    "        Select al;l negative samples and 100 sampled negative items for each user.\n",
    "        \"\"\"\n",
    "        # 构造user-item表\n",
    "        interact_status = ratings.groupby('userId')['itemId'].apply(set).reset_index().rename(\n",
    "            columns={'itemId': 'interacted_items'})\n",
    "        print(\"interact_status: \\n\", interact_status)\n",
    "\n",
    "        # 把与用户没有产生过交互的样本都当做是负样本\n",
    "        interact_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: self._itemPool - x)\n",
    "\n",
    "        # 从上面的全部负样本中随机选99个出来\n",
    "        interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, 99))\n",
    "        print(\"after sampling interact_status: \\n\", interact_status)\n",
    "\n",
    "        print(\"select and rearrange columns\")\n",
    "        self._negatives = interact_status[['userId', 'negative_items', 'negative_samples']]\n",
    "\n",
    "    def _split_pool(self, ratings):\n",
    "        \"\"\"leave one out train/test split \"\"\"\n",
    "        print(\"sort by timestamp descend\")\n",
    "        # 先按照'userID'进行分组，然后根据时间戳降序排列\n",
    "        ratings['rank_latest'] = ratings.groupby(['userId'])['timestamp'].rank(method='first', ascending=False)\n",
    "        print(ratings)\n",
    "\n",
    "        # 选取排名第一的数据作为测试集，也就是最新的那个数据\n",
    "        test = ratings[ratings['rank_latest'] == 1]\n",
    "        # 选取所有排名靠后的，也就是历史数据当做训练集\n",
    "        train = ratings[ratings['rank_latest'] > 1]\n",
    "        # print(\"test: \\n\", test)\n",
    "        # print(\"train: \\n\", train)\n",
    "\n",
    "        print(\"size of test {0}, size of train {1}\".format(len(test), len(train)))\n",
    "\n",
    "        # 确保训练集和测试集的userId是一样的\n",
    "        assert train['userId'].nunique() == test['userId'].nunique()\n",
    "\n",
    "        self.train_ratings = train[['userId', 'itemId', 'rating']]\n",
    "        self.test_ratings = test[['userId', 'itemId', 'rating']]\n",
    "\n",
    "    def sample_generator(self, num_negatives):\n",
    "        # 合并之后的train_ratings的列包括['userId','itemId'，'rating','negative_items']\n",
    "        train_ratings = pd.merge(self.train_ratings, self._negatives[['userId', 'negative_items']], on='userId')\n",
    "        # 从用户的全部负样本集合中随机选择num_negatives个样本当做负样本，并产生一个新的名为\"negatives\"的列\n",
    "        train_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, num_negatives))\n",
    "        print(train_ratings)\n",
    "\n",
    "        # 构造模型所需要的数据，分别是输入user、items以及目标分值ratings。\n",
    "        users, items, ratings = [], [], []\n",
    "        for row in train_ratings.itertuples():\n",
    "            # 构造正样本，分别是userId， itemId以及目标分值1\n",
    "            users.append(int(row.userId))\n",
    "            items.append(int(row.itemId))\n",
    "            ratings.append(float(row.rating))\n",
    "            # 为每个用户构造num_negatives个负样本，分别是userId， itemId以及目标分值0\n",
    "            for i in range(num_negatives):\n",
    "                users.append(int(row.userId))\n",
    "                items.append(int(row.negatives[i]))\n",
    "                ratings.append(float(0)) # 负样本的ratings为0，直接强行设置为0\n",
    "\n",
    "        return users, items, ratings\n",
    "    \n",
    "    def test_neg_generator(self, num_negatives):\n",
    "        # 合并之后的test_ratings的列包括['userId','itemId'，'rating','negative_items']\n",
    "        test_ratings = pd.merge(self.test_ratings, self._negatives[['userId', 'negative_items']], on='userId')\n",
    "        # 从用户的全部负样本集合中随机选择num_negatives个样本当做负样本，并产生一个新的名为\"negatives\"的列\n",
    "        test_ratings['negatives'] = test_ratings['negative_items'].apply(lambda x: random.sample(x, num_negatives))\n",
    "        for i in range(len(test_ratings['negatives'])):\n",
    "            if i in sust:\n",
    "                test_ratings['negatives'][i] = zip(test_ratings['negatives'][i], 1)\n",
    "            else:\n",
    "                test_ratings['negatives'][i] = zip(test_ratings['negatives'][i], 0)\n",
    "        print(test_ratings)\n",
    "\n",
    "        # 构造模型所需要的数据，分别是输入user、items以及目标分值ratings。\n",
    "        users, items, ratings = [], [], []\n",
    "        for row in test_ratings.itertuples():\n",
    "            # 构造正样本，分别是userId， itemId以及目标分值1\n",
    "            users.append(int(row.userId))\n",
    "            items.append(int(row.itemId))\n",
    "            ratings.append(float(row.rating))\n",
    "            # 为每个用户构造num_negatives个负样本，分别是userId， itemId以及目标分值0\n",
    "            for i in range(num_negatives):\n",
    "                users.append(int(row.userId))\n",
    "                items.append(int(row.negatives[i]))\n",
    "                ratings.append(float(0)) # 负样本的ratings为0，直接强行设置为0\n",
    "\n",
    "        return test_ratings\n",
    "\n",
    "sust_data = pd.read_csv(\n",
    "\t\t'sust.csv', header=None, names=['susItem'], dtype={0: np.int32})\n",
    "sust = sust_data['susItem'].unique().values.tolist()\n",
    "\n",
    "mag = DataProcess('sampledData.csv')\n",
    "\n",
    "# generating files for test and train ratings\n",
    "train_ratings = mag.train_ratings\n",
    "train_ratings.to_csv('ml-1m.train.rating.csv',header=None, index=None)\n",
    "test_ratings = mag.test_ratings\n",
    "test_ratings.to_csv('ml-1m.test.rating.csv',header=None, index=None)\n",
    "\n",
    "# generating file for test negative\n",
    "ndf = mag.test_neg_generator(99)\n",
    "ndf['uispair'] = list(zip(ndf.userId, ndf.itemId))\n",
    "\n",
    "ndf2 = ndf.loc[:, ['uipair','negatives']]\n",
    "ndf2.to_csv('ml-1m.test.negative.csv',sep='\\t', header=None, index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4903d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating file for sustainable items\n",
    "susRatings = mag._originalRatings[mag._originalRatings['sust']==1]\n",
    "susRatings['itemId'].to_csv('sust.csv',header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35285a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n"
     ]
    }
   ],
   "source": [
    "print(len(susRatings['itemId'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf4cf55",
   "metadata": {},
   "source": [
    "### (trial) filter user based on duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import os\n",
    "sampled1 = pd.read_csv('sampledData.csv',names=['uid','mid','rating','timestamp','sust'])\n",
    "sampled1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18495536",
   "metadata": {},
   "outputs": [],
   "source": [
    "noLabel2 = sampled1[sampled1['sust']==0]\n",
    "is_multi = noLabel2['uid'].value_counts()>5\n",
    "noLabel3 = noLabel2[noLabel2['uid'].isin(is_multi[is_multi].index)]\n",
    "noLabel3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d483aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(noLabel3['uid'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433ff5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "withLabel = sampled1[sampled1['sust']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b105ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.concat([noLabel3,withLabel])\n",
    "finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf87554",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(finalDf['uid'].unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AmazonRecSys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aec2b49f0b156ccbd13eb3ced1f831c079eaadace1c55dfffcf3bc16a9a14954"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
