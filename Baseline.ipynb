{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "922b4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5ac67f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_data=pd.read_csv('Magazine_Subscriptions.csv',names=['productId','userID','Rating','timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb05f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    productId          userID  Rating   timestamp\n",
      "0  B00005N7P0   AH2IFH762VY5U     5.0  1005177600\n",
      "1  B00005N7P0   AOSFI0JEYU4XM     5.0  1004486400\n",
      "2  B00005N7OJ  A3JPFWKS83R49V     3.0  1174694400\n",
      "3  B00005N7OJ  A19FKU6JZQ2ECJ     5.0  1163116800\n",
      "4  B00005N7P0  A25MDGOMZ2GALN     5.0  1405296000\n"
     ]
    }
   ],
   "source": [
    "print(ma_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85019e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_multi=ma_data['userID'].value_counts()>1\n",
    "filtered = ma_data[ma_data['userID'].isin(is_multi[is_multi].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e553b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     productId          userID  Rating   timestamp\n",
      "2   B00005N7OJ  A3JPFWKS83R49V     3.0  1174694400\n",
      "4   B00005N7P0  A25MDGOMZ2GALN     5.0  1405296000\n",
      "7   B00005N7P0    AC2278WPK3EU     5.0  1400112000\n",
      "9   B00005N7P0   A5QQOOZJOVPSF     4.0  1393372800\n",
      "10  B00005N7P0  A1Z16630QMH8Q6     5.0  1388880000\n"
     ]
    }
   ],
   "source": [
    "print(filtered.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85955889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "class DataProcess(object):\n",
    "    def __init__(self, filename):\n",
    "        self._filename = filename\n",
    "        self._loadData()\n",
    "        self._preProcess()\n",
    "        self._binarize(self._originalRatings)\n",
    "        # 对'userId'这一列的数据，先去重，然后构成一个用户列表\n",
    "        self._userPool = set(self._originalRatings['userId'].unique())\n",
    "        self._itemPool = set(self._originalRatings['itemId'].unique())\n",
    "        print(\"user_pool size: \", len(self._userPool))\n",
    "        print(\"item_pool size: \", len(self._itemPool))\n",
    "\n",
    "        self._select_Negatives(self._originalRatings)\n",
    "        self._split_pool(self._preprocessRatings)\n",
    "\n",
    "    def _loadData(self):\n",
    "        self._originalRatings = pd.read_csv(self._filename,names=['mid','uid','rating','timestamp'])\n",
    "        is_multi=self._originalRatings['uid'].value_counts()>1\n",
    "        self._originalRatings = self._originalRatings[self._originalRatings['uid'].isin(is_multi[is_multi].index)]\n",
    "        return self._originalRatings\n",
    "\n",
    "    def _preProcess(self):\n",
    "        \"\"\"\n",
    "        对user和item都重新编号，这里这么做的原因是因为，模型的输入是one-hot向量，需要把user和item都限制在Embedding的长度之内，\n",
    "        模型的两个输入的长度分别是user和item的数量，所以要重新从0编号。\n",
    "        \"\"\"\n",
    "        # 1. 新建名为\"userId\"的列，这列对用户从0开始编号\n",
    "        user_id = self._originalRatings[['uid']].drop_duplicates().reindex()\n",
    "        user_id['userId'] = np.arange(len(user_id)) #根据user的长度创建一个数组\n",
    "        # 将原先的DataFrame与user_id按照\"uid\"这一列进行合并\n",
    "        self._originalRatings = pd.merge(self._originalRatings, user_id, on=['uid'], how='left')\n",
    "\n",
    "        # 2. 对物品进行重新排列\n",
    "        item_id = self._originalRatings[['mid']].drop_duplicates()\n",
    "        item_id['itemId'] = np.arange(len(item_id))\n",
    "        self._originalRatings = pd.merge(self._originalRatings, item_id, on=['mid'], how='left')\n",
    "\n",
    "        # 按照['userId', 'itemId', 'rating', 'timestamp']的顺序重新排列\n",
    "        self._originalRatings = self._originalRatings[['userId', 'itemId', 'rating', 'timestamp']]\n",
    "        print(self._originalRatings)\n",
    "        print('Range of userId is [{}, {}]'.format(self._originalRatings.userId.min(), self._originalRatings.userId.max()))\n",
    "        print('Range of itemId is [{}, {}]'.format(self._originalRatings.itemId.min(), self._originalRatings.itemId.max()))\n",
    "\n",
    "    def _binarize(self, ratings):\n",
    "        \"\"\"\n",
    "        binarize data into 0 or 1 for implicit feedback\n",
    "        \"\"\"\n",
    "        ratings = deepcopy(ratings)\n",
    "        ratings['rating'][ratings['rating'] > 0] = 1.0\n",
    "        self._preprocessRatings = ratings\n",
    "        # print(\"binary: \\n\", self._preprocessRatings)\n",
    "\n",
    "    def _select_Negatives(self, ratings):\n",
    "        \"\"\"\n",
    "        Select al;l negative samples and 100 sampled negative items for each user.\n",
    "        \"\"\"\n",
    "        # 构造user-item表\n",
    "        interact_status = ratings.groupby('userId')['itemId'].apply(set).reset_index().rename(\n",
    "            columns={'itemId': 'interacted_items'})\n",
    "        print(\"interact_status: \\n\", interact_status)\n",
    "\n",
    "        # 把与用户没有产生过交互的样本都当做是负样本\n",
    "        interact_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: self._itemPool - x)\n",
    "\n",
    "        # 从上面的全部负样本中随机选99个出来\n",
    "        interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, 99))\n",
    "        print(\"after sampling interact_status: \\n\", interact_status)\n",
    "\n",
    "        print(\"select and rearrange columns\")\n",
    "        self._negatives = interact_status[['userId', 'negative_items', 'negative_samples']]\n",
    "\n",
    "    def _split_pool(self, ratings):\n",
    "        \"\"\"leave one out train/test split \"\"\"\n",
    "        print(\"sort by timestamp descend\")\n",
    "        # 先按照'userID'进行分组，然后根据时间戳降序排列\n",
    "        ratings['rank_latest'] = ratings.groupby(['userId'])['timestamp'].rank(method='first', ascending=False)\n",
    "        print(ratings)\n",
    "\n",
    "        # 选取排名第一的数据作为测试集，也就是最新的那个数据\n",
    "        test = ratings[ratings['rank_latest'] == 1]\n",
    "        # 选取所有排名靠后的，也就是历史数据当做训练集\n",
    "        train = ratings[ratings['rank_latest'] > 1]\n",
    "        # print(\"test: \\n\", test)\n",
    "        # print(\"train: \\n\", train)\n",
    "\n",
    "        print(\"size of test {0}, size of train {1}\".format(len(test), len(train)))\n",
    "\n",
    "        # 确保训练集和测试集的userId是一样的\n",
    "        assert train['userId'].nunique() == test['userId'].nunique()\n",
    "\n",
    "        self.train_ratings = train[['userId', 'itemId', 'rating']]\n",
    "        self.test_ratings = test[['userId', 'itemId', 'rating']]\n",
    "\n",
    "    def sample_generator(self, num_negatives):\n",
    "        # 合并之后的train_ratings的列包括['userId','itemId'，'rating','negative_items']\n",
    "        train_ratings = pd.merge(self.train_ratings, self._negatives[['userId', 'negative_items']], on='userId')\n",
    "        # 从用户的全部负样本集合中随机选择num_negatives个样本当做负样本，并产生一个新的名为\"negatives\"的列\n",
    "        train_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, num_negatives))\n",
    "        print(train_ratings)\n",
    "\n",
    "        # 构造模型所需要的数据，分别是输入user、items以及目标分值ratings。\n",
    "        users, items, ratings = [], [], []\n",
    "        for row in train_ratings.itertuples():\n",
    "            # 构造正样本，分别是userId， itemId以及目标分值1\n",
    "            users.append(int(row.userId))\n",
    "            items.append(int(row.itemId))\n",
    "            ratings.append(float(row.rating))\n",
    "            # 为每个用户构造num_negatives个负样本，分别是userId， itemId以及目标分值0\n",
    "            for i in range(num_negatives):\n",
    "                users.append(int(row.userId))\n",
    "                items.append(int(row.negatives[i]))\n",
    "                ratings.append(float(0)) # 负样本的ratings为0，直接强行设置为0\n",
    "\n",
    "        return users, items, ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b95648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237612b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId  itemId  rating   timestamp\n",
      "0           0       0     3.0  1174694400\n",
      "1           1       1     5.0  1405296000\n",
      "2           2       1     5.0  1400112000\n",
      "3           3       1     4.0  1393372800\n",
      "4           4       1     5.0  1388880000\n",
      "...       ...     ...     ...         ...\n",
      "28672   11085    1649     3.0  1488412800\n",
      "28673   11053    1649     3.0  1484611200\n",
      "28674    4180    1649     5.0  1480291200\n",
      "28675   10540    1649     5.0  1471737600\n",
      "28676   10404    1649     5.0  1469923200\n",
      "\n",
      "[28677 rows x 4 columns]\n",
      "Range of userId is [0, 11085]\n",
      "Range of itemId is [0, 1649]\n",
      "user_pool size:  11086\n",
      "item_pool size:  1650\n",
      "interact_status: \n",
      "        userId                                   interacted_items\n",
      "0           0  {0, 1, 258, 4, 263, 10, 141, 269, 15, 144, 657...\n",
      "1           1                                 {1, 498, 1143, 31}\n",
      "2           2                                      {1, 302, 479}\n",
      "3           3                          {1, 67, 71, 280, 348, 93}\n",
      "4           4                                            {1, 17}\n",
      "...       ...                                                ...\n",
      "11081   11081                                 {1618, 1622, 1623}\n",
      "11082   11082                                 {1620, 1621, 1623}\n",
      "11083   11083                                        {1623, 815}\n",
      "11084   11084                                         {820, 821}\n",
      "11085   11085                                       {1649, 1646}\n",
      "\n",
      "[11086 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/dskbnhqd7b5blhf0z346yn600000gn/T/ipykernel_5949/4154988305.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ratings['rating'][ratings['rating'] > 0] = 1.0\n",
      "/var/folders/k1/dskbnhqd7b5blhf0z346yn600000gn/T/ipykernel_5949/4154988305.py:73: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, 99))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after sampling interact_status: \n",
      "        userId                                   interacted_items  \\\n",
      "0           0  {0, 1, 258, 4, 263, 10, 141, 269, 15, 144, 657...   \n",
      "1           1                                 {1, 498, 1143, 31}   \n",
      "2           2                                      {1, 302, 479}   \n",
      "3           3                          {1, 67, 71, 280, 348, 93}   \n",
      "4           4                                            {1, 17}   \n",
      "...       ...                                                ...   \n",
      "11081   11081                                 {1618, 1622, 1623}   \n",
      "11082   11082                                 {1620, 1621, 1623}   \n",
      "11083   11083                                        {1623, 815}   \n",
      "11084   11084                                         {820, 821}   \n",
      "11085   11085                                       {1649, 1646}   \n",
      "\n",
      "                                          negative_items  \\\n",
      "0      {2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, ...   \n",
      "1      {0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "2      {0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "3      {0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "4      {0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "...                                                  ...   \n",
      "11081  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "11082  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "11083  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "11084  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "11085  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "\n",
      "                                        negative_samples  \n",
      "0      [840, 1607, 914, 108, 580, 1101, 1048, 882, 67...  \n",
      "1      [1258, 1348, 535, 978, 143, 185, 1394, 1555, 2...  \n",
      "2      [896, 371, 126, 1034, 959, 81, 1224, 207, 1435...  \n",
      "3      [344, 918, 134, 536, 1442, 327, 920, 1086, 100...  \n",
      "4      [557, 684, 693, 1619, 754, 1473, 193, 694, 159...  \n",
      "...                                                  ...  \n",
      "11081  [1452, 1054, 535, 62, 1036, 1123, 256, 889, 53...  \n",
      "11082  [626, 777, 112, 444, 580, 1470, 323, 1296, 112...  \n",
      "11083  [240, 457, 512, 1636, 527, 1082, 1376, 1306, 3...  \n",
      "11084  [1298, 422, 1402, 520, 197, 620, 1365, 5, 784,...  \n",
      "11085  [1283, 1428, 721, 1481, 1114, 1168, 950, 293, ...  \n",
      "\n",
      "[11086 rows x 4 columns]\n",
      "select and rearrange columns\n",
      "sort by timestamp descend\n",
      "       userId  itemId  rating   timestamp  rank_latest\n",
      "0           0       0     1.0  1174694400         29.0\n",
      "1           1       1     1.0  1405296000          1.0\n",
      "2           2       1     1.0  1400112000          1.0\n",
      "3           3       1     1.0  1393372800          1.0\n",
      "4           4       1     1.0  1388880000          1.0\n",
      "...       ...     ...     ...         ...          ...\n",
      "28672   11085    1649     1.0  1488412800          2.0\n",
      "28673   11053    1649     1.0  1484611200          1.0\n",
      "28674    4180    1649     1.0  1480291200          3.0\n",
      "28675   10540    1649     1.0  1471737600          3.0\n",
      "28676   10404    1649     1.0  1469923200          2.0\n",
      "\n",
      "[28677 rows x 5 columns]\n",
      "size of test 11086, size of train 17591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/dskbnhqd7b5blhf0z346yn600000gn/T/ipykernel_5949/4154988305.py:105: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  train_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, num_negatives))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId  itemId  rating  \\\n",
      "0           0       0     1.0   \n",
      "1           0       4     1.0   \n",
      "2           0       1     1.0   \n",
      "3           0      15     1.0   \n",
      "4           0      30     1.0   \n",
      "...       ...     ...     ...   \n",
      "17586   10939     829     1.0   \n",
      "17587    4529     829     1.0   \n",
      "17588    8826     829     1.0   \n",
      "17589   11085    1649     1.0   \n",
      "17590   10404    1649     1.0   \n",
      "\n",
      "                                          negative_items  \\\n",
      "0      {2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, ...   \n",
      "1      {2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, ...   \n",
      "2      {2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, ...   \n",
      "3      {2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, ...   \n",
      "4      {2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, ...   \n",
      "...                                                  ...   \n",
      "17586  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "17587  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "17588  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "17589  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "17590  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "\n",
      "                                               negatives  \n",
      "0      [1548, 1343, 1521, 707, 1347, 535, 1621, 648, ...  \n",
      "1      [644, 1645, 1302, 5, 967, 200, 446, 849, 744, ...  \n",
      "2      [476, 1091, 672, 650, 1325, 894, 1587, 1164, 5...  \n",
      "3      [1458, 960, 1246, 503, 452, 543, 1632, 1565, 1...  \n",
      "4      [941, 597, 632, 173, 560, 762, 1515, 1370, 445...  \n",
      "...                                                  ...  \n",
      "17586  [32, 269, 878, 600, 5, 1069, 1185, 991, 1087, ...  \n",
      "17587  [257, 504, 60, 1365, 589, 1213, 770, 782, 375,...  \n",
      "17588  [389, 385, 507, 1599, 630, 1170, 705, 1242, 84...  \n",
      "17589  [1140, 299, 737, 1265, 34, 332, 636, 477, 877,...  \n",
      "17590  [825, 118, 258, 864, 1331, 1347, 449, 509, 713...  \n",
      "\n",
      "[17591 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mag = DataProcess('Magazine_Subscriptions.csv')\n",
    "print(mag.sample_generator(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c81bfae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCF(object):\n",
    "    def __init__(self, config, latent_dim_gmf=8, latent_dim_mlp=8):\n",
    "        self._config = config\n",
    "        self._num_users = config['num_users']\n",
    "        self._num_items = config['num_items']\n",
    "        self._latent_dim_gmf = latent_dim_gmf\n",
    "        self._latent_dim_mlp = latent_dim_mlp\n",
    "\n",
    "        # 建立MLP模型的user Embedding层和item Embedding层，输入的向量长度分别为用户的数量，item的数量，输出都是隐式空间的维度latent dim\n",
    "        self._embedding_user_mlp = torch.nn.Embedding(num_embeddings=self._num_users, embedding_dim=self._latent_dim_mlp)\n",
    "        self._embedding_item_mlp = torch.nn.Embedding(num_embeddings=self._num_users, embedding_dim=self._latent_dim_mlp)\n",
    "        # 建立GMP模型的user Embedding层和item Embedding层，输入的向量长度分别为用户的数量，item的数量，输出都是隐式空间的维度latent dim\n",
    "        self._embedding_user_gmf = torch.nn.Embedding(num_embeddings=self._num_users, embedding_dim=self._latent_dim_gmf)\n",
    "        self._embedding_item_gmf = torch.nn.Embedding(num_embeddings=self._num_users, embedding_dim=self._latent_dim_gmf)\n",
    "\n",
    "        # 全连接层\n",
    "        self._fc_layers = torch.nn.ModuleList()\n",
    "        for idx, (in_size, out_size) in enumerate(zip(config['layers'][:-1], config['layers'][1:])):\n",
    "            self._fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "\n",
    "        # 激活函数\n",
    "        self._logistic = nn.Sigmoid()\n",
    "\n",
    "    @property\n",
    "    def fc_layers(self):\n",
    "        return self._fc_layers\n",
    "\n",
    "    @property\n",
    "    def embedding_user_gmf(self):\n",
    "        return self._embedding_user_gmf\n",
    "\n",
    "    @property\n",
    "    def embedding_item_gmf(self):\n",
    "        return self._embedding_item_gmf\n",
    "\n",
    "    @property\n",
    "    def embedding_user_mlp(self):\n",
    "        return self._embedding_user_mlp\n",
    "\n",
    "    @property\n",
    "    def embedding_item_mlp(self):\n",
    "        return self._embedding_item_mlp\n",
    "\n",
    "    def saveModel(self):\n",
    "        torch.save(self.state_dict(), self._config['model_name'])\n",
    "\n",
    "#     @abstractmethod\n",
    "    def load_preTrained_weights(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f8b8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(NCF, nn.Module):\n",
    "    def __init__(self, config, latent_dim_gmf):\n",
    "        nn.Module.__init__(self)\n",
    "        NCF.__init__(self, config=config, latent_dim_gmf=latent_dim_gmf)\n",
    "        # 创建一个线性模型，输入为潜在特征向量，输出向量长度为1\n",
    "        self._affine_output = nn.Linear(in_features=self._latent_dim_gmf, out_features=1)\n",
    "\n",
    "    @property\n",
    "    def affine_output(self):\n",
    "        return self._affine_output\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param user_indices: user Tensor\n",
    "        :param item_indices: item Tensor\n",
    "        :return: predicted rating\n",
    "        \"\"\"\n",
    "        # 先将user和item转换为对应的Embedding表示，注意这个支持Tensor操作，即传入的是一个user列表，对其中每一个user都会执行Embedding操作，即都会使用Embedding表示\n",
    "        user_embedding = self._embedding_user_gmf(user_indices)\n",
    "        item_embedding = self._embedding_item_gmf(item_indices)\n",
    "        # 对user_embedding和user_embedding进行逐元素相乘, 这一步其实就是MF算法的实现\n",
    "        element_product = torch.mul(user_embedding, item_embedding)\n",
    "        # 将逐元素的乘积的结果通过一个S型神经元\n",
    "        logits = self._affine_output(element_product)\n",
    "        rating = self._logistic(logits)\n",
    "        return rating\n",
    "\n",
    "    def load_preTrained_weights(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce625b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(NCF, nn.Module):\n",
    "    def __init__(self, config, latent_dim_mlp):\n",
    "        nn.Module.__init__(self)\n",
    "        NCF.__init__(self, config=config, latent_dim_mlp=latent_dim_mlp)\n",
    "        # 创建一个线性模型，输入为潜在特征向量，输出向量长度为1\n",
    "        self._affine_output = torch.nn.Linear(in_features=config['layers'][-1], out_features=1)\n",
    "\n",
    "    @property\n",
    "    def affine_output(self):\n",
    "        return self._affine_output\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        \"\"\"\n",
    "        :param user_indices: user Tensor\n",
    "        :param item_indices: item Tensor\n",
    "        \"\"\"\n",
    "        # 先将user和item转换为对应的Embedding表示，注意这个支持Tensor操作，即传入的是一个user列表，\n",
    "        # 对其中每一个user都会执行Embedding操作，即都会使用Embedding表示\n",
    "        user_embedding = self._embedding_user_mlp(user_indices)\n",
    "        item_embedding = self._embedding_item_mlp(item_indices)\n",
    "        vector = torch.cat([user_embedding, item_embedding], dim=-1) # concat latent vector\n",
    "        for idx, _ in enumerate(range(len(self._fc_layers))):\n",
    "            vector = self._fc_layers[idx](vector)\n",
    "            vector = torch.nn.ReLU()(vector)\n",
    "            ##  Batch normalization\n",
    "            # vector = torch.nn.BatchNorm1d()(vector)\n",
    "            ## DroupOut layer\n",
    "            # vector = torch.nn.Dropout(p=0.5)(vector)\n",
    "        logits = self._affine_output(vector)\n",
    "        rating = self._logistic(logits)\n",
    "        return rating\n",
    "\n",
    "    def load_preTrained_weights(self):\n",
    "        config = self._config\n",
    "        gmf_model = GMF(config, config['latent_dim_gmf'])\n",
    "#         if config['use_cuda'] is True:\n",
    "#             gmf_model.cuda()\n",
    "#         # 加载GMF模型参数到指定的GPU上\n",
    "#         state_dict = torch.load(self._config['pretrain_gmf'])\n",
    "#                                 #map_location=lambda storage, loc: storage.cuda(device=self._config['device_id']))\n",
    "#                                 #map_location = {'cuda:0': 'cpu'})\n",
    "        gmf_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        self._embedding_item_mlp.weight.data = gmf_model.embedding_item_gmf.weight.data\n",
    "        self._embedding_user_mlp.weight.data = gmf_model.embedding_user_gmf.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a425f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(NCF, nn.Module):\n",
    "    def __init__(self, config, latent_dim_gmf, latent_dim_mlp):\n",
    "        nn.Module.__init__(self)\n",
    "        NCF.__init__(self, config, latent_dim_gmf, latent_dim_mlp)\n",
    "\n",
    "        # 创建一个线性模型，输入为GMF模型和MLP模型的潜在特征向量长度之和，输出向量长度为1\n",
    "        self._affine_output = torch.nn.Linear(in_features=config['layers'][-1] + config['latent_dim_gmf'], out_features=1)\n",
    "\n",
    "    @property\n",
    "    def affine_output(self):\n",
    "        return self._affine_output\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding_mlp = self._embedding_user_mlp(user_indices)\n",
    "        item_embedding_mlp = self._embedding_item_mlp(item_indices)\n",
    "        user_embedding_gmf = self._embedding_user_gmf(user_indices)\n",
    "        item_embedding_gmf = self._embedding_item_gmf(item_indices)\n",
    "\n",
    "        # concat the two latent vector\n",
    "        mlp_vector = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1)\n",
    "        # multiply the two latent vector\n",
    "        gmf_vector = torch.mul(user_embedding_gmf, item_embedding_gmf)\n",
    "\n",
    "        for idx, _ in enumerate(range(len(self._fc_layers))):\n",
    "            mlp_vector = self._fc_layers[idx](mlp_vector)\n",
    "            mlp_vector = torch.nn.ReLU()(mlp_vector)\n",
    "\n",
    "        vector = torch.cat([mlp_vector, gmf_vector], dim=-1)\n",
    "        logits = self._affine_output(vector)\n",
    "        rating = self._logistic(logits)\n",
    "        return rating\n",
    "\n",
    "    def load_preTrained_weights(self):\n",
    "        # 加载MLP模型参数\n",
    "        mlp_model = MLP(self._config['mlp_config'], self._config['mlp_config']['latent_dim_mlp'])\n",
    "        if self._config['use_cuda'] is True:\n",
    "            mlp_model.cuda()\n",
    "        state_dict = torch.load(self._config['pretrain_mlp'])\n",
    "                                # map_location=lambda storage, loc: storage.cuda(device=self._config['device_id']))\n",
    "                                # map_location = {'cuda:0': 'cpu'})\n",
    "        mlp_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        self._embedding_item_mlp.weight.data = mlp_model.embedding_item_mlp.weight.data\n",
    "        self._embedding_user_mlp.weight.data = mlp_model.embedding_user_mlp.weight.data\n",
    "        for idx in range(len(self._fc_layers)):\n",
    "            self._fc_layers[idx].weight.data = mlp_model.fc_layers[idx].weight.data\n",
    "\n",
    "        # 加载GMF模型参数\n",
    "        gmf_model = GMF(self._config['gmf_config'], self._config['gmf_config']['latent_dim_gmf'])\n",
    "        if self._config['use_cuda'] is True:\n",
    "            gmf_model.cuda()\n",
    "        state_dict = torch.load(self._config['pretrain_gmf'])\n",
    "                                # map_location=lambda storage, loc: storage.cuda(device=self._config['device_id']))\n",
    "                                # map_location = {'cuda:0': 'cpu'})\n",
    "        mlp_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        self._embedding_item_gmf.weight.data = gmf_model.embedding_item_gmf.weight.data\n",
    "        self._embedding_user_gmf.weight.data = gmf_model.embedding_user_gmf.weight.data\n",
    "\n",
    "        self._affine_output.weight.data = self._config['alpha'] * torch.cat([mlp_model.affine_output.weight.data, gmf_model.affine_output.weight.data], dim=-1)\n",
    "        self._affine_output.bias.data = self._config['alpha'] * (mlp_model.affine_output.bias.data + gmf_model.affine_output.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da5751d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_optimizer(network, params):\n",
    "    optimizer = None\n",
    "    if params['optimizer'] == 'sgd':\n",
    "        optimizer = torch.optim.SGD(network.parameters(),\n",
    "                                    lr=params['sgd_lr'],\n",
    "                                    momentum=params['sgd_momentum'],\n",
    "                                    weight_decay=params['l2_regularization'])\n",
    "    elif params['optimizer'] == 'adam':\n",
    "        optimizer = torch.optim.Adam(network.parameters(),\n",
    "                                     lr=params['adam_lr'],\n",
    "                                     weight_decay=params['l2_regularization'])\n",
    "    elif params['optimizer'] == 'rmsprop':\n",
    "        optimizer = torch.optim.RMSprop(network.parameters(),\n",
    "                                        lr=params['rmsprop_lr'],\n",
    "                                        alpha=params['rmsprop_alpha'],\n",
    "                                        momentum=params['rmsprop_momentum'])\n",
    "    return optimizer\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, model, config):\n",
    "        self._config = config\n",
    "        self._model = model\n",
    "        # 选择优化器\n",
    "        self._optimizer = pick_optimizer(self._model, self._config)\n",
    "        # 定义损失函数，对于隐反馈数据，这里使用交叉熵损失函数\n",
    "        self._crit = torch.nn.BCELoss()\n",
    "\n",
    "    def _train_single_batch(self, users, items, ratings):\n",
    "        \"\"\"\n",
    "        对单个小批量数据进行训练\n",
    "        :param users: user Tensor\n",
    "        :param items: item Tensor\n",
    "        :param ratings: rating Tensor\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self._config['use_cuda'] is True:\n",
    "            # 将这些数据由CPU迁移到GPU\n",
    "            users, items, ratings = users.cuda(), items.cuda(), ratings.cuda()\n",
    "\n",
    "        # 先将梯度清零,如果不清零，那么这个梯度就和上一个mini-batch有关\n",
    "        self._optimizer.zero_grad()\n",
    "        # 模型的输入users， items，调用forward进行前向传播\n",
    "        ratings_pred = self._model(users, items)\n",
    "        # 通过交叉熵损失函数来计算损失, ratings_pred.view(-1)代表将预测结果摊平，变成一维的结构。\n",
    "        loss = self._crit(ratings_pred.view(-1), ratings)\n",
    "        # 反向传播计算梯度\n",
    "        loss.backward()\n",
    "        # 梯度下降等优化器 更新参数\n",
    "        self._optimizer.step()\n",
    "        # 将loss的值提取成python的float类型\n",
    "        loss = loss.item()\n",
    "        return loss\n",
    "\n",
    "    def _train_an_epoch(self, train_loader, epoch_id):\n",
    "        \"\"\"\n",
    "        训练一个Epoch，即将训练集中的所有样本全部都过一遍\n",
    "        :param train_loader: Torch的DataLoader\n",
    "        :param epoch_id: 训练轮次Id\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 告诉模型目前处于训练模式，启用dropout以及batch normalization\n",
    "        self._model.train()\n",
    "        total_loss = 0\n",
    "        # 从DataLoader中获取小批量的id以及数据\n",
    "        for batch_id, batch in enumerate(train_loader):\n",
    "            assert isinstance(batch[0], torch.LongTensor)\n",
    "            # 这里的user, item, rating大小变成了1024维了，因为batch_size是1024，即每次选取1024个样本数据进行训练\n",
    "            user, item, rating = batch[0], batch[1], batch[2]\n",
    "            rating = rating.float()\n",
    "            loss = self._train_single_batch(user, item, rating)\n",
    "            print('[Training Epoch {}] Batch {}, Loss {}'.format(epoch_id, batch_id, loss))\n",
    "            total_loss += loss\n",
    "        print('Training Epoch: {}, TotalLoss: {}'.format(epoch_id, total_loss))\n",
    "\n",
    "    def train(self, sampleGenerator):\n",
    "        # 是否使用GPU加速\n",
    "#         self.use_cuda()\n",
    "        # 是否使用预先训练好的参数\n",
    "        self.load_preTrained_weights()\n",
    "\n",
    "        for epoch in range(self._config['num_epoch']):\n",
    "            print('-' * 20 + ' Epoch {} starts '.format(epoch) + '-' * 20)\n",
    "            # 每个轮次都重新随机产生样本数据集\n",
    "            users, items, ratings = sampleGenerator(num_negatives=self._config['num_negative'])\n",
    "            # 构造一个DataLoader\n",
    "            data_loader = Construct_DataLoader(users=users, items=items, ratings=ratings,\n",
    "                                               batchsize=self._config['batch_size'])\n",
    "            # 训练一个轮次\n",
    "            self._train_an_epoch(data_loader, epoch_id=epoch)\n",
    "\n",
    "    def use_cuda(self):\n",
    "        if self._config['use_cuda'] is True:\n",
    "            assert torch.cuda.is_available(), 'CUDA is not available'\n",
    "            torch.cuda.set_device(self._config['device_id'])\n",
    "            self._model.cuda()\n",
    "\n",
    "    def load_preTrained_weights(self):\n",
    "        if self._config['pretrain'] is True:\n",
    "            self._model.load_preTrained_weights()\n",
    "\n",
    "    def save(self):\n",
    "        self._model.saveModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a21b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf_config = {'alias': 'gmf_factor8neg4-implict',\n",
    "              'num_epoch': 200,\n",
    "              'batch_size': 1024,\n",
    "              # 'optimizer': 'sgd',\n",
    "              # 'sgd_lr': 1e-3,\n",
    "              # 'sgd_momentum': 0.9,\n",
    "              # 'optimizer': 'rmsprop',\n",
    "              # 'rmsprop_lr': 1e-3,\n",
    "              # 'rmsprop_alpha': 0.99,\n",
    "              # 'rmsprop_momentum': 0,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': 6040,\n",
    "              'num_items': 3706,\n",
    "              'latent_dim': 8,\n",
    "              'num_negative': 4,\n",
    "              'l2_regularization': 0, # 0.01\n",
    "              'use_cuda': True,\n",
    "              'device_id': 0,\n",
    "              'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}\n",
    "\n",
    "mlp_config = {'alias': 'mlp_factor8neg4_bz256_166432168_pretrain_reg_0.0000001',\n",
    "              'num_epoch': 200,\n",
    "              'batch_size': 256,  # 1024,\n",
    "              'optimizer': 'adam',\n",
    "              'adam_lr': 1e-3,\n",
    "              'num_users': 6040,\n",
    "              'num_items': 3706,\n",
    "              'latent_dim': 8,\n",
    "              'num_negative': 4,\n",
    "              'layers': [16,64,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "              'l2_regularization': 0.0000001,  # MLP model is sensitive to hyper params\n",
    "              'use_cuda': True,\n",
    "              'device_id': 7,\n",
    "              'pretrain': True,\n",
    "              'pretrain_mf': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "              'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'}\n",
    "\n",
    "neumf_config = {'alias': 'pretrain_neumf_factor8neg4',\n",
    "                'num_epoch': 200,\n",
    "                'batch_size': 1024,\n",
    "                'optimizer': 'adam',\n",
    "                'adam_lr': 1e-3,\n",
    "                'num_users': 6040,\n",
    "                'num_items': 3706,\n",
    "                'latent_dim_gmf': 8,\n",
    "                'latent_dim_mlp': 8,\n",
    "                'num_negative': 4,\n",
    "                'layers': [16,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "                'l2_regularization': 0.01,\n",
    "                'use_cuda': True,\n",
    "                'device_id': 7,\n",
    "                'pretrain': True,\n",
    "                'pretrain_mf': 'checkpoints/{}'.format('gmf_factor8neg4_Epoch100_HR0.6391_NDCG0.2852.model'),\n",
    "                'pretrain_mlp': 'checkpoints/{}'.format('mlp_factor8neg4_Epoch100_HR0.5606_NDCG0.2463.model'),\n",
    "                'model_dir':'checkpoints/{}_Epoch{}_HR{:.4f}_NDCG{:.4f}.model'\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "601656e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userId  itemId  rating   timestamp\n",
      "0           0       0     3.0  1174694400\n",
      "1           1       1     5.0  1405296000\n",
      "2           2       1     5.0  1400112000\n",
      "3           3       1     4.0  1393372800\n",
      "4           4       1     5.0  1388880000\n",
      "...       ...     ...     ...         ...\n",
      "28672   11085    1649     3.0  1488412800\n",
      "28673   11053    1649     3.0  1484611200\n",
      "28674    4180    1649     5.0  1480291200\n",
      "28675   10540    1649     5.0  1471737600\n",
      "28676   10404    1649     5.0  1469923200\n",
      "\n",
      "[28677 rows x 4 columns]\n",
      "Range of userId is [0, 11085]\n",
      "Range of itemId is [0, 1649]\n",
      "user_pool size:  11086\n",
      "item_pool size:  1650\n",
      "interact_status: \n",
      "        userId                                   interacted_items\n",
      "0           0  {0, 1, 258, 4, 263, 10, 141, 269, 15, 144, 657...\n",
      "1           1                                 {1, 498, 1143, 31}\n",
      "2           2                                      {1, 302, 479}\n",
      "3           3                          {1, 67, 71, 280, 348, 93}\n",
      "4           4                                            {1, 17}\n",
      "...       ...                                                ...\n",
      "11081   11081                                 {1618, 1622, 1623}\n",
      "11082   11082                                 {1620, 1621, 1623}\n",
      "11083   11083                                        {1623, 815}\n",
      "11084   11084                                         {820, 821}\n",
      "11085   11085                                       {1649, 1646}\n",
      "\n",
      "[11086 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/dskbnhqd7b5blhf0z346yn600000gn/T/ipykernel_95613/4154988305.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ratings['rating'][ratings['rating'] > 0] = 1.0\n",
      "/var/folders/k1/dskbnhqd7b5blhf0z346yn600000gn/T/ipykernel_95613/4154988305.py:73: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, 99))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after sampling interact_status: \n",
      "        userId                                   interacted_items  \\\n",
      "0           0  {0, 1, 258, 4, 263, 10, 141, 269, 15, 144, 657...   \n",
      "1           1                                 {1, 498, 1143, 31}   \n",
      "2           2                                      {1, 302, 479}   \n",
      "3           3                          {1, 67, 71, 280, 348, 93}   \n",
      "4           4                                            {1, 17}   \n",
      "...       ...                                                ...   \n",
      "11081   11081                                 {1618, 1622, 1623}   \n",
      "11082   11082                                 {1620, 1621, 1623}   \n",
      "11083   11083                                        {1623, 815}   \n",
      "11084   11084                                         {820, 821}   \n",
      "11085   11085                                       {1649, 1646}   \n",
      "\n",
      "                                          negative_items  \\\n",
      "0      {2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 17, ...   \n",
      "1      {0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "2      {0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "3      {0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "4      {0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   \n",
      "...                                                  ...   \n",
      "11081  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "11082  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "11083  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "11084  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "11085  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
      "\n",
      "                                        negative_samples  \n",
      "0      [1146, 961, 1047, 5, 27, 62, 1320, 575, 903, 2...  \n",
      "1      [684, 1472, 1357, 377, 448, 243, 449, 1439, 43...  \n",
      "2      [1577, 384, 1477, 573, 36, 1545, 351, 1089, 10...  \n",
      "3      [1082, 513, 1357, 1600, 1333, 1181, 827, 846, ...  \n",
      "4      [805, 1075, 222, 1533, 559, 1456, 1200, 1046, ...  \n",
      "...                                                  ...  \n",
      "11081  [1201, 1431, 1408, 1103, 850, 28, 867, 1393, 1...  \n",
      "11082  [579, 550, 666, 241, 447, 905, 304, 1191, 1169...  \n",
      "11083  [437, 781, 1613, 142, 602, 1146, 137, 747, 591...  \n",
      "11084  [1211, 428, 30, 533, 45, 1118, 267, 851, 982, ...  \n",
      "11085  [544, 1561, 1404, 677, 1618, 1106, 252, 1278, ...  \n",
      "\n",
      "[11086 rows x 4 columns]\n",
      "select and rearrange columns\n",
      "sort by timestamp descend\n",
      "       userId  itemId  rating   timestamp  rank_latest\n",
      "0           0       0     1.0  1174694400         29.0\n",
      "1           1       1     1.0  1405296000          1.0\n",
      "2           2       1     1.0  1400112000          1.0\n",
      "3           3       1     1.0  1393372800          1.0\n",
      "4           4       1     1.0  1388880000          1.0\n",
      "...       ...     ...     ...         ...          ...\n",
      "28672   11085    1649     1.0  1488412800          2.0\n",
      "28673   11053    1649     1.0  1484611200          1.0\n",
      "28674    4180    1649     1.0  1480291200          3.0\n",
      "28675   10540    1649     1.0  1471737600          3.0\n",
      "28676   10404    1649     1.0  1469923200          2.0\n",
      "\n",
      "[28677 rows x 5 columns]\n",
      "size of test 11086, size of train 17591\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mlp_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [50]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# ###############################################################\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 模型训练阶段\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# ###############################################################\u001b[39;00m\n\u001b[1;32m     24\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m---> 25\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# ###############################################################\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# 模型测试阶段\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# ###############################################################\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# 加载数据集\u001b[39;00m\n",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, sampleGenerator)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, sampleGenerator):\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;66;03m# 是否使用GPU加速\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m#         self.use_cuda()\u001b[39;00m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;66;03m# 是否使用预先训练好的参数\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_preTrained_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     82\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m20\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m starts \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m20\u001b[39m)\n",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36mTrainer.load_preTrained_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_preTrained_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretrain\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_preTrained_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36mNeuMF.load_preTrained_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_preTrained_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# 加载MLP模型参数\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     mlp_model \u001b[38;5;241m=\u001b[39m MLP(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmlp_config\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlp_config\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatent_dim_mlp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_cuda\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m         mlp_model\u001b[38;5;241m.\u001b[39mcuda()\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mlp_config'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ####################################################################################\n",
    "    # NCF 神经协同过滤算法\n",
    "    ####################################################################################\n",
    "\n",
    "    # 加载和预处理数据\n",
    "    dp = DataProcess(\"Magazine_Subscriptions.csv\")\n",
    "\n",
    "    # 初始化GMP模型\n",
    "    # config = gmf_config\n",
    "    # model = GMF(config, config['latent_dim_gmf'])\n",
    "\n",
    "    # # 初始化MLP模型\n",
    "    # config = mlp_config\n",
    "    # model = MLP(config, config['latent_dim_mlp'])\n",
    "\n",
    "    # 初始化NeuMF模型\n",
    "    config = neumf_config\n",
    "    model = NeuMF(config, config['latent_dim_gmf'], config['latent_dim_mlp'])\n",
    "\n",
    "    # ###############################################################\n",
    "    # 模型训练阶段\n",
    "    # ###############################################################\n",
    "    trainer = Trainer(model=model, config=config)\n",
    "    trainer.train(dp.sample_generator)\n",
    "    trainer.save()\n",
    "\n",
    "    # ###############################################################\n",
    "    # 模型测试阶段\n",
    "    # ###############################################################\n",
    "\n",
    "    # 加载数据集\n",
    "    dp = DataProcess(\"Magazine_Subscriptions.csv\")\n",
    "\n",
    "    config = neumf_config\n",
    "    neumf = NeuMF(config, config['latent_dim_gmf'], config['latent_dim_mlp'])\n",
    "    state_dict = torch.load(\"../Models/NCF_NeuMF.model\", map_location=torch.device('cpu'))\n",
    "    neumf.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    print(neumf.forward(torch.LongTensor([1]), torch.LongTensor([1193])))\n",
    "    print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([661])))\n",
    "    print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([914])))\n",
    "    print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([3408])))\n",
    "\n",
    "    print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([1245])))\n",
    "    print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([32])))\n",
    "    print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([4])))\n",
    "    print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([62])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e02d3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
